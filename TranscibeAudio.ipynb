{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMSJH5aBn9LGiO4YmqIIcmT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaranDharshanSP/Whisper-Test/blob/main/TranscibeAudio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!sudo apt update && sudo apt install ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nywr1dXAtsGQ",
        "outputId": "724532fe-eccc-445b-b46a-5c4faf6373ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-2yx_psf4\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-2yx_psf4\n",
            "  Resolved https://github.com/openai/whisper.git to commit fcfeaf1b61994c071bba62da47d7846933576ac9\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting triton==2.0.0 (from openai-whisper==20231106)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper==20231106)\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20231106) (3.27.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20231106) (3.13.1)\n",
            "Collecting lit (from triton==2.0.0->openai-whisper==20231106)\n",
            "  Downloading lit-17.0.4.tar.gz (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.1/153.1 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231106) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231106) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231106) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (2023.6.0)\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torch (from openai-whisper==20231106)\n",
            "  Downloading torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m109.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch (from openai-whisper==20231106)\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m120.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper==20231106) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper==20231106) (0.41.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231106) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231106) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper, lit\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231106-py3-none-any.whl size=801353 sha256=dbb75754267bfc6cdaf08e5f91056c152b75d5d9a2ae5d2fc2e174a71afc6fcc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1fj4297r/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-17.0.4-py3-none-any.whl size=93257 sha256=fc8027dcefce485ca9d1681a18ea486599ae0665363dc86f79cb17a3168afd4f\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/ae/00/696c57d438bfc7c0e89c4c379083ea08b1c2e54d85a5f7cd7c\n",
            "Successfully built openai-whisper lit\n",
            "Installing collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, tiktoken, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, openai-whisper\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.1.0\n",
            "    Uninstalling triton-2.1.0:\n",
            "      Successfully uninstalled triton-2.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu118\n",
            "    Uninstalling torch-2.1.0+cu118:\n",
            "      Successfully uninstalled torch-2.1.0+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-17.0.4 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 openai-whisper-20231106 tiktoken-0.5.1 torch-2.0.1 triton-2.0.0\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Get:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:8 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,192 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,274 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,461 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:14 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main Sources [2,240 kB]\n",
            "Get:15 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main amd64 Packages [1,150 kB]\n",
            "Fetched 7,677 kB in 5s (1,633 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "19 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper \"Badass-MassTamilan.dev.mp3\" --model medium.en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZjV3PL1tszo",
        "outputId": "5c50eb05-a43c-4b06-dfd1-ec53ba15812d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████████████████████████████████| 1.42G/1.42G [00:11<00:00, 134MiB/s]\n",
            "[00:30.000 --> 01:00.000]  Aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo\n",
            "[01:00.000 --> 01:30.000]  Aye yo, aye yo, aye yo, aye yo, aye yo,\n",
            "[01:30.000 --> 02:00.000]  aye yo, aye yo, aye yo, aye yo, aye yo,\n",
            "[02:00.000 --> 02:30.000]  aye yo Aye yo, aye yo, aye yo, aye yo, aye yo,\n",
            "[02:30.000 --> 03:00.000]  aye yo, aye yo, aye yo, aye yo,\n",
            "[03:00.000 --> 03:30.000]  aye yo Aye yo, aye yo, aye yo, aye yo,\n",
            "[03:30.000 --> 03:49.690]  aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo, aye yo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper \"Badass-MassTamilan.dev.mp3\" --language ta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVQG1_zLxVQA",
        "outputId": "6bcfaadb-bcc8-425a-ff83-19a37c5d8287"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:00.000 --> 00:30.000]  செய்துவிட்டுவிட்டுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவ\n",
            "[00:30.000 --> 00:41.320]  காரணே மந்தை நகாத்திடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிடுவிd Tapi Emot lag\n",
            "[00:41.720 --> 00:44.120]  Y буду des couples\n",
            "[00:44.120 --> 00:46.640]  சிங அ வி அ நா காட்கே வ இருந்து\n",
            "[00:46.640 --> 00:49.240]  இவர் வேட்டைக்கு செடரணோம் வைத்து\n",
            "[00:49.320 --> 00:51.840]  வெறுபுளிக்கெல்லாம் முட்டு புளி எழுதி\n",
            "[00:51.840 --> 00:54.320]  காடல் நொரு பிரச்சம்ப RYANுதி\n",
            "[00:54.320 --> 00:59.040]  இது வழையில் நல்லமையிருந்தான்\n",
            "[00:59.040 --> 01:03.260]  நினைக்கரையில் ராஜஞாதம் ஊருந்தான்\n",
            "[01:04.260 --> 01:07.600]  பதிக்குச்சியில் இ ஏிரிمழமாவம் அணை\n",
            "[01:07.600 --> 01:12.520]  ஏறிங்காத நீக்க, கூலச் ஐயந்திக்கமாமே\n",
            "[01:12.520 --> 01:14.360]  ஒரேக்காத நீக்க\n",
            "[01:14.360 --> 01:19.560]  தெ அட்குமா something automovid\n",
            "[01:19.560 --> 01:24.660]  பாடாஷ்மா, கோபால குறிட்டு\n",
            "[01:24.660 --> 01:29.960]  பாடாச்மா, நிவர் காஸ்மா,\n",
            "[01:29.960 --> 01:34.880]  பாடாஷ்மா, குறாச்சா, மோடிட்டு\n",
            "[01:34.880 --> 01:41.180]  பேர times தலின்டாணி recommendations\n",
            "[01:41.180 --> 01:48.300]  பேர задач நியோ\n",
            "[01:49.560 --> 01:51.560]  லியோ\n",
            "[01:55.560 --> 01:57.560]  பலரா ஜக்கலப்பா தச்சிடா\n",
            "[01:57.560 --> 02:01.560]  இவன்கா தீரம்பா கூராச்சிடா\n",
            "[02:01.560 --> 02:02.560]  லியோ\n",
            "[02:02.560 --> 02:03.560]  லியோ\n",
            "[02:03.560 --> 02:04.560]  லியோ\n",
            "[02:04.560 --> 02:06.560]  தெரிதா\n",
            "[02:06.560 --> 02:08.560]  பூர் பஞ்சாய் எத்தி தச்சிடா\n",
            "[02:08.560 --> 02:11.560]  வரலா ரிம்பதம் பிள்டாச்சிடா\n",
            "[02:11.560 --> 02:12.560]  லியோ\n",
            "[02:12.560 --> 02:13.560]  லியோ\n",
            "[02:13.560 --> 02:14.560]  லியோ\n",
            "[02:14.560 --> 02:15.560]  தெரிதா\n",
            "[02:15.560 --> 02:17.560]  தரும்ப\n",
            "[02:17.560 --> 02:18.560]  ரொம்ப\n",
            "[02:18.560 --> 02:21.560]  ஆடாதம் மா\n",
            "[02:21.560 --> 02:22.560]  பெரிக்க\n",
            "[02:22.560 --> 02:23.560]  பெரிக்க\n",
            "[02:23.560 --> 02:26.560] 阿டி பார்க் மா\n",
            "[02:27.560 --> 02:29.060]  வரை ஆக்க\n",
            "[02:30.560 --> 02:31.560]  இரு மலமாவா,\n",
            "[02:31.560 --> 02:32.560]  நே\n",
            "[02:32.560 --> 02:33.560]  ரெரிக்காதட்டு\n",
            "[02:33.560 --> 02:34.560]  ரெரிக்காதட்டு\n",
            "[02:34.560 --> 02:36.560]  போல்லதஸ்மிய பெரிந்திக்கமா\n",
            "[02:36.560 --> 02:37.560]  மே\n",
            "[02:37.560 --> 02:38.560]  உறைக்காதட்டு\n",
            "[02:38.560 --> 02:39.560]  ரெரிக்காதட்டு\n",
            "[02:39.560 --> 02:41.560]  பிடாக்குமா\n",
            "[02:41.560 --> 02:43.560]  ஒரம் மோர்படு\n",
            "[02:44.560 --> 02:46.560]  பிடாக்குமா\n",
            "[02:46.560 --> 02:49.180]  உன் பாளைக் குழித்துடு\n",
            "[02:49.180 --> 02:54.500]  பெடால் சுமா, நீயைப் தாசுமா\n",
            "[02:54.500 --> 02:59.840]  பெடால் சுமா, உறங்கு ராத்தாமமூம் வோட்டிடு\n",
            "[02:59.840 --> 03:07.540]  ஹரின் ஌பله டாஸ், ஹரின் ஌பின் டாஸ்\n",
            "[03:07.540 --> 03:37.540]  ஏன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன்\n",
            "[03:37.540 --> 03:42.220]  அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன் அன்\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper \"06 NEW MAGIC WAND (feat. Santigold & Jessy Wilson).mp3\" --model medium.en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrJPSstMv_j4",
        "outputId": "7d171dce-d400-4c44-fbfe-20239e9e7ffe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:00.000 --> 00:03.000]  Sometimes you gotta close the door to open a window.\n",
            "[00:31.000 --> 00:34.000]  Like magic, like magic, like magic, what?\n",
            "[00:34.000 --> 00:37.000]  Like magic, like magic, like magic, what?\n",
            "[00:37.000 --> 00:41.000]  Like magic, like magic, like magic, what?\n",
            "[00:41.000 --> 00:43.000]  Like magic, like magic, like magic, what?\n",
            "[00:43.000 --> 00:45.000]  My brother said I'm on the spectrum\n",
            "[00:46.000 --> 00:48.000]  Don't call me selfish, I hate sharin'\n",
            "[00:49.000 --> 00:52.000]  It's 60, 40, workin'\n",
            "[00:53.000 --> 00:55.000]  I want a hundred of your time\n",
            "[00:56.000 --> 00:57.000]  Your mind\n",
            "[00:58.000 --> 01:00.000]  Please don't leave me now\n",
            "[01:01.000 --> 01:04.000]  Please don't leave me now\n",
            "[01:09.000 --> 01:10.000]  Don't leave me now\n",
            "[01:11.000 --> 01:12.000]  Please don't leave me now\n",
            "[01:13.000 --> 01:15.000]  Like magic, like magic, like magic, what?\n",
            "[01:16.000 --> 01:18.000]  Like magic, like magic, like magic, what?\n",
            "[01:19.000 --> 01:20.000]  Please don't leave me now\n",
            "[01:21.000 --> 01:22.000]  Please don't leave me now\n",
            "[01:23.000 --> 01:24.000]  Please don't leave me now\n",
            "[01:25.000 --> 01:26.000]  I hate sharin'\n",
            "[01:27.000 --> 01:29.000]  I'm a young passenger in a young car\n",
            "[01:29.000 --> 01:32.000]  You what you need, make sure this don't pop\n",
            "[01:32.000 --> 01:35.000]  She's gonna be dead, I just gotta make one\n",
            "[01:35.000 --> 01:38.000]  We can finally be together\n",
            "[01:40.000 --> 01:43.000]  Roll the dice, hit a seven, show you right\n",
            "[01:43.000 --> 01:46.000]  Beginners love it, you're not my first, who gives a fuck?\n",
            "[01:46.000 --> 01:50.000]  You're other one, evaporate, we celebrate\n",
            "[01:50.000 --> 01:53.000]  You under oath, I pick a sign, if you don't\n",
            "[01:53.000 --> 01:55.000]  I'll pick you both\n",
            "[01:58.000 --> 02:00.000]  It's not a joke\n",
            "[02:02.000 --> 02:04.000]  I'ma rip she broke\n",
            "[02:20.000 --> 02:23.000]  Take one look in the mirror, implications so clear\n",
            "[02:23.000 --> 02:25.000]  I live life with no fear, except for the idea\n",
            "[02:25.000 --> 02:28.000]  That one day you won't be here, I will not fetch the bar\n",
            "[02:28.000 --> 02:30.000]  Eyes are green, I eat my vegetables\n",
            "[02:30.000 --> 02:32.000]  It has nothing to do with that bar\n",
            "[02:32.000 --> 02:34.000]  But if it did, guarantee she'd be gone\n",
            "[02:34.000 --> 02:36.000]  I got a plan with the walk in the pen\n",
            "[02:36.000 --> 02:38.000]  If you can't understand, I'm a hawk in the gym\n",
            "[02:38.000 --> 02:39.000]  Eyes on the clock, got a wave on my chest\n",
            "[02:39.000 --> 02:41.000]  I need to pick off, I ain't talking to them\n",
            "[02:41.000 --> 02:43.000]  Can't be in the picture if it got no frame\n",
            "[02:43.000 --> 02:44.000]  Don't let the world know, cause I ain't got no shame\n",
            "[02:44.000 --> 02:46.000]  Blow the whole spot up tonight\n",
            "[02:46.000 --> 02:48.000]  I wanna share last names, I wanna be your number one\n",
            "[02:48.000 --> 02:50.000]  Not the other one, keep it on the lower\n",
            "[02:50.000 --> 02:52.000]  I'm in my right mind, drip it on the high, high drain\n",
            "[02:52.000 --> 02:53.000]  And shot the lens, fill it, fill it\n",
            "[02:53.000 --> 02:54.000]  Now I'm out here mopping up, foot on the floor\n",
            "[02:54.000 --> 02:56.000]  Pack up your bags, we hit the store\n",
            "[02:56.000 --> 02:58.000]  Grab our supplies, no need for masks\n",
            "[02:58.000 --> 03:00.000]  Bust through the door, get the job done like the time that I'm in\n",
            "[03:00.000 --> 03:02.000]  You look concerned, you magic wand\n"
          ]
        }
      ]
    }
  ]
}